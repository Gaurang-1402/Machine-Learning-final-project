{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Important Libraries\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing # preprossing is what we do with the data before we run the learning algorithm\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "# import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 2.]\n",
      " [0. 0. 0. ... 0. 0. 2.]\n",
      " [0. 0. 0. ... 0. 0. 2.]\n",
      " ...\n",
      " [2. 2. 0. ... 0. 0. 1.]\n",
      " [2. 1. 0. ... 2. 0. 0.]\n",
      " [2. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Load the .arff file\n",
    "connect_4_dataset = arff.loadarff('../connect-4.arff')\n",
    "\n",
    "# Convert to a numpy array\n",
    "data = np.asarray(connect_4_dataset[0].tolist(), dtype=np.float32)\n",
    "\n",
    "# Print the array\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "Scale after splitting the data into train and test since we will be using gradient ascent. \n",
    "* Use `train_test_split` to split the data (`75% train` and `25% test`) to `X_train`, `X_test`, `y_train`, `y_test` with `random_state` of 42\n",
    "* Reshape `y_train` into 2D array `y_2d_train` and `y_test` into 2D array `y_2d_test`\n",
    "* Augment the dataset with a column of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(67557, 42)\n",
      "y:(67557, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "print('X:' + str(X.shape))\n",
    "print('y:' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5804.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'X_train_val, X_test, y_train_val, y_test = train_test_split(\\n    X, y,   \\n    test_size = 0.07, random_state=10, shuffle=True\\n)\\n\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X, y, \\n    test_size = 0.7, stratify=np.array([0.33, 0.33, 0.34]),\\n    random_state=10, shuffle=True\\n)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# extract the classes\n",
    "X_zeros = X[y == 0]\n",
    "y_zeros = y[y == 0]\n",
    "X_ones = X[y == 1]\n",
    "y_ones = y[y == 1]\n",
    "X_twos = X[y == 2]\n",
    "y_twos = y[y == 2]\n",
    "\n",
    "# how many of each class the training set should have\n",
    "# 90% of the smallest class\n",
    "amount_per_class = (min(len(y_zeros), len(y_ones), len(y_twos))) * 0.9\n",
    "print(amount_per_class)\n",
    "\n",
    "X_zeros_train, X_zeros_test, y_zeros_train, y_zeros_test = train_test_split(\n",
    "    X_zeros, y_zeros,\n",
    "    test_size=1-(amount_per_class/len(y_zeros)),\n",
    "    random_state=10, shuffle=True\n",
    ")\n",
    "X_ones_train, X_ones_test, y_ones_train, y_ones_test = train_test_split(\n",
    "    X_ones, y_ones,\n",
    "    test_size=1-(amount_per_class/len(y_ones)),\n",
    "    random_state=10, shuffle=True\n",
    ")\n",
    "X_twos_train, X_twos_test, y_twos_train, y_twos_test = train_test_split(\n",
    "    X_twos, y_twos,\n",
    "    test_size=1-(amount_per_class/len(y_twos)),\n",
    "    random_state=10, shuffle=True\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_zeros_train, X_ones_train, X_twos_train))\n",
    "y_train = np.concatenate((y_zeros_train, y_ones_train, y_twos_train))\n",
    "X_val = np.concatenate((X_zeros_test, X_ones_test, X_twos_test))\n",
    "y_val = np.concatenate((y_zeros_test, y_ones_test, y_twos_test))\n",
    "\n",
    "'''X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,   \n",
    "    test_size = 0.07, random_state=10, shuffle=True\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size = 0.7, stratify=np.array([0.33, 0.33, 0.34]),\n",
    "    random_state=10, shuffle=True\n",
    ")'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting the dataset \n",
    "\n",
    "# X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "#     X, y,   \n",
    "#     test_size = 0.07, random_state=10, shuffle=True\n",
    "# )\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train_val, y_train_val, \n",
    "#     test_size = 0.07, random_state=10, shuffle=True\n",
    "# )\n",
    "\n",
    "# y_train = y_train.ravel()\n",
    "# y_test = y_test.ravel()\n",
    "# y_val = y_val.ravel()\n",
    "\n",
    "# # ! No need to scale since the data is already the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "X_val = np.hstack((np.ones((X_val.shape[0], 1)), X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(17412, 43)\n",
      "y_train:(17412,)\n",
      "X_val: \t(50145, 43)\n",
      "y_val: \t(50145,)\n",
      "X_test: (50145, 43)\n",
      "y_test: (50145,)\n",
      "X_train:(43,)\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure everything is as expected\n",
    "print('X_train:' + str(X_train.shape))\n",
    "print('y_train:' + str(y_train.shape))\n",
    "print('X_val: \\t'  + str(X_val.shape))\n",
    "print('y_val: \\t'  + str(y_val.shape))\n",
    "print('X_test: '  + str(X_test.shape))\n",
    "print('y_test: '  + str(y_test.shape))\n",
    "\n",
    "print('X_train:' + str(X_train[0].shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original labels are '0', '1', '2'. Our SVM algorithm Pegasos expects the labels to be encoded as +1 and -1\n",
    "# Here we encode one digit as 1, and we encode the other 2 digits as -1\n",
    "def one_vs_rest_encoding(y, digit = '0'):\n",
    "    y_encoded = np.where(y == int(digit), 1, -1)\n",
    "    return  y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the encoding for step 1's task\n",
    "y_train_0_vs_rest = one_vs_rest_encoding(y_train, '0')\n",
    "y_val_0_vs_rest =  one_vs_rest_encoding(y_val, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_0_vs_rest: [ 1  1  1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print('y_train_0_vs_rest: ' + str(y_train_0_vs_rest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! SVM with RBF kernel\n",
    "# # Create the 3 classifiers\n",
    "# labels = \"012\"\n",
    "# w_vals = {}\n",
    "# val_scores = {}\n",
    "# for i in range(len(labels)):\n",
    "#     # Note that each section may require more than one line of code.\n",
    "\n",
    "#     # Perform one-vs-rest for labels[i]\n",
    "#     # To do: Relabel the y labels in the train set to either 1 or -1 using one_vs_rest_encoding\n",
    "#     y_encoded = one_vs_rest_encoding(y_train, labels[i])\n",
    "\n",
    "#     svm_algo = svm.SVC(kernel='rbf', C=0.001)\n",
    "\n",
    "#     svm_algo.fit(X_train, y_encoded)\n",
    "\n",
    "#     # TODO: Get the weights (coefficients) of the SVM model and store them in w_vals[i]\n",
    "#     # Note that the decision function oaf an SVM with RBF kernel is not a linear combination of the\n",
    "#     # features, so there are no coefficients to directly compare to those of a linear SVM.\n",
    "#     # However, you can still access the dual coefficients of the support vectors using the dual_coef_ attribute.\n",
    "#     # For example, you can compute the weights as a weighted sum of the support vectors, where the dual coefficients\n",
    "#     # are the weights. See the scikit-learn documentation for details.\n",
    "#     support_vectors = svm_algo.support_vectors_\n",
    "#     dual_coef = svm_algo.dual_coef_.reshape(1, -1, 1)\n",
    "#     w = np.sum(dual_coef * support_vectors, axis=1)\n",
    "#     w_vals[i] = w.reshape(1, -1)\n",
    "\n",
    "#     y_pred_val = svm_algo.predict(X_val)\n",
    "\n",
    "#     y_encoded_val = one_vs_rest_encoding(y_val, labels[i])\n",
    "\n",
    "#     # compute the accuracy of the classifier\n",
    "#     val_accuracy = accuracy_score(y_encoded_val, y_pred_val)\n",
    "\n",
    "#     val_scores[i] = val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3 classifiers\n",
    "labels = \"012\"\n",
    "w_vals = {}\n",
    "val_scores = {}\n",
    "for i in range(len(labels)):\n",
    "    # Note that each section may require more than one line of code.\n",
    "\n",
    "    # Perform one-vs-rest for labels[i]\n",
    "    # To do: Relabel the y labels in the train set to either 1 or -1 using one_vs_rest_encoding\n",
    "    y_encoded = one_vs_rest_encoding(y_train, labels[i])\n",
    "\n",
    "    svm_algo = svm.SVC(kernel='poly', degree=3, C=0.001)\n",
    "    \n",
    "    svm_algo.fit(X_train, y_encoded)\n",
    "\n",
    "    # TODO: Get the weights (coefficients) of the SVM model and store them in w_vals[i]\n",
    "    # Note that the decision function oaf an SVM with RBF kernel is not a linear combination of the\n",
    "    # features, so there are no coefficients to directly compare to those of a linear SVM.\n",
    "    # However, you can still access the dual coefficients of the support vectors using the dual_coef_ attribute.\n",
    "    # For example, you can compute the weights as a weighted sum of the support vectors, where the dual coefficients\n",
    "    # are the weights. See the scikit-learn documentation for details.\n",
    "    support_vectors = svm_algo.support_vectors_\n",
    "    dual_coef = svm_algo.dual_coef_.reshape(1, -1, 1)\n",
    "    w = np.sum(dual_coef * support_vectors, axis=1)\n",
    "    w_vals[i] = w.reshape(1, -1)\n",
    "\n",
    "    y_pred_val = svm_algo.predict(X_val)\n",
    "\n",
    "    y_encoded_val = one_vs_rest_encoding(y_val, labels[i])\n",
    "\n",
    "    # compute the accuracy of the classifier\n",
    "    val_accuracy = accuracy_score(y_encoded_val, y_pred_val)\n",
    "\n",
    "    val_scores[i] = val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : score: 0.9871373018247084\n",
      "1 : score: 0.7840063814936684\n",
      "2 : score: 0.2288563166816233\n"
     ]
    }
   ],
   "source": [
    "# Check your work. With the proper amount of iterations, your values should range from 0.95 to 0.99  \n",
    "for i in range(len(labels)):\n",
    "     print(i,\": score:\", val_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: Predict the label for each example in the validation set \n",
    "# We will let eval be a numpy array of length N, where N is the number of examples in the validation set. \n",
    "# eval1 will hold either a 1 or a 0, depending if the handwritten digit was predicted correctly or not.\n",
    "eval1 = np.zeros(len(y_val))\n",
    "\n",
    "# To do: Loop through each sample in the validation set and assign it a label based on the highest score. \n",
    "# Store either a 1 if the number was predicted correctly, or a 0 if the number was predicted incorrectly.\n",
    "for i in range(len(X_val)):\n",
    "    \n",
    "    label_scores = np.zeros(len(labels))\n",
    "    \n",
    "    for j in range(len(labels)):\n",
    "        X_val_i_2d = X_val[i].reshape(1, -1)  # reshape X_val to a 2D array with shape (1, 43)\n",
    "        # print('X_val: \\t'  + str(X_val_i_2d.shape))\n",
    "        # print('w_vals: \\t'  + str(w_vals[j].shape))\n",
    "        label_scores[j] = X_val_i_2d @ w_vals[j].T\n",
    "    \n",
    "    # print(label_scores)\n",
    "    index = np.argmax(label_scores) # get the index of the label with the highest score\n",
    "    \n",
    "    # print(\"index: \", int(labels[index]))\n",
    "    # print(\"y_val: \", int(y_val[i]))\n",
    "    # print(\"==============\")\n",
    "    if int(labels[index]) == int(y_val[i]):\n",
    "        eval1[i] = 1\n",
    "    else:\n",
    "        eval1[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.5201914448100509\n"
     ]
    }
   ],
   "source": [
    "# To do: Determine how many were predicted correctly (Find its accuracy score)\n",
    "accuracy = np.sum(eval1) / len(y_val)\n",
    "print(\"Accuracy Score:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_to_ml_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
